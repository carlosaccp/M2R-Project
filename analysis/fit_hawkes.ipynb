{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hawkes fit to start times\n",
    "Load the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import scipy.optimize as op\n",
    "plt.style.use(\"dark_background\") # Config plots for dark mode, delete if on light mode\n",
    "plt.rcParams['figure.dpi'] = 150 # Hi-res plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the station data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(\"../data/santander_locations.csv\")\n",
    "station_data.head() # Load the station data and inspect the first 5 rows\n",
    "class StationIdError(IndexError):\n",
    "    \"\"\"Called when we try and read a non-existing station Id\"\"\"\n",
    "    pass\n",
    "\n",
    "def get_station_name(in_id):\n",
    "    \"\"\"Get station name from bike_data for a given id, catching any exceptions\"\"\"\n",
    "    try:\n",
    "        return station_data[station_data[\"Station.Id\"] == in_id].StationName.iloc[0]\n",
    "    except IndexError:\n",
    "        StationIdError(\"No station matching input ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the start times to make them pseudo-continuous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data = pd.read_csv(\"../data/processed_df.csv\", index_col=0)\n",
    "bike_data.head() # Load the processed bike data and inspect the first 5 rows\n",
    "\n",
    "# Find minimum start time\n",
    "x = bike_data.min()[\"start_time\"]\n",
    "t_min = (x // 86400) * 86400\n",
    "\n",
    "# Substract t_min from start_time and end_time\n",
    "bike_data[\"start_time\"] = (bike_data[\"start_time\"] - t_min) / 60\n",
    "bike_data[\"end_time\"] = (bike_data[\"end_time\"] - t_min) / 60\n",
    "\n",
    "# Introduce random perturbations to make pseudo-continuous\n",
    "bike_data[\"start_time\"] = bike_data[\"start_time\"] + np.random.rand(*bike_data[\"start_time\"].shape)\n",
    "bike_data[\"end_time\"] = bike_data[\"end_time\"] + np.random.rand(*bike_data[\"end_time\"].shape)\n",
    "\n",
    "bike_data[\"duration\"] = bike_data.end_time - bike_data.start_time\n",
    "bike_data = bike_data.sort_values(by=[\"start_time\"])\n",
    "\n",
    "train_time = 12*7*24*60\n",
    "train_bike_data = bike_data[bike_data.start_time <= train_time]\n",
    "train_bike_data.head()\n",
    "\n",
    "train_sorted_stations = []\n",
    "for st_id in train_bike_data.start_id.sort_values().unique():\n",
    "    train_sorted_stations.append(train_bike_data[train_bike_data.start_id==st_id])\n",
    "\n",
    "train_sorted_stations[0].head()\n",
    "\n",
    "rates_dict = {}\n",
    "for station in train_sorted_stations:\n",
    "    time_elapsed = station.start_time.to_numpy()[-1] - station.start_time.to_numpy()[0]\n",
    "    n_events = train_sorted_stations[0].size\n",
    "    rate = n_events / time_elapsed\n",
    "\n",
    "    rates_dict[station.start_id.unique()[0]]= rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following kernel:\n",
    "$$\n",
    "\\mu_i(t) = \\alpha_i e^{-\\beta_i t},\\, 0 \\leq \\alpha_i \\leq \\beta_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-122435.850871605"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genA(i, beta, t):\n",
    "    if i == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.exp(-1*beta*(t[i] - t[i-1]))*(1+genA(i-1, beta, t))\n",
    "\n",
    "def hawkes_log_likelihood(t, alpha, beta, lambda_p): \n",
    "    A = []\n",
    "    for i in range(0, len(t)):\n",
    "        if i==0:\n",
    "            A.append(0)\n",
    "        else:\n",
    "            A.append(np.exp(-1*beta*(t[i] - t[i-1]))*(1+A[i-1]))\n",
    "    l = 0\n",
    "    for i in range(0, len(t)):\n",
    "        l += np.log(lambda_p + alpha*A[i]) + (alpha/beta) * (np.exp(-beta*(t[-1] - t[i])) - 1)\n",
    "    l -= lambda_p * t[-1]\n",
    "    return l\n",
    "\n",
    "hawkes_log_likelihood(train_sorted_stations[0].start_time.to_numpy(),1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(alpha) = log(beta + alpha)\n",
    "# op_hawkes_likelihood = lambda x: -hawkes_log_likelihood(station.start_time.to_numpy(), np.exp(x[0]), np.exp(x[1]), np.exp(x[2]) + np.exp(x[1]))\n",
    "#Â x0 = [1,2,10]\n",
    "# To constrain, take exp, and to revert take log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/t8qzqs6x2f19402hdk543xd80000gn/T/ipykernel_22680/3045833632.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  l += np.log(lambda_p + alpha*A[i]) + (alpha/beta) * (np.exp(-beta*(t[-1] - t[i])) - 1)\n",
      "/var/folders/82/t8qzqs6x2f19402hdk543xd80000gn/T/ipykernel_22680/3045833632.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  l += np.log(lambda_p + alpha*A[i]) + (alpha/beta) * (np.exp(-beta*(t[-1] - t[i])) - 1)\n",
      "/var/folders/82/t8qzqs6x2f19402hdk543xd80000gn/T/ipykernel_22680/3045833632.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  l += np.log(lambda_p + alpha*A[i]) + (alpha/beta) * (np.exp(-beta*(t[-1] - t[i])) - 1)\n",
      "/var/folders/82/t8qzqs6x2f19402hdk543xd80000gn/T/ipykernel_22680/3045833632.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  l += np.log(lambda_p + alpha*A[i]) + (alpha/beta) * (np.exp(-beta*(t[-1] - t[i])) - 1)\n",
      "/var/folders/82/t8qzqs6x2f19402hdk543xd80000gn/T/ipykernel_22680/3045833632.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  l += np.log(lambda_p + alpha*A[i]) + (alpha/beta) * (np.exp(-beta*(t[-1] - t[i])) - 1)\n",
      "/var/folders/82/t8qzqs6x2f19402hdk543xd80000gn/T/ipykernel_22680/3045833632.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  l += np.log(lambda_p + alpha*A[i]) + (alpha/beta) * (np.exp(-beta*(t[-1] - t[i])) - 1)\n"
     ]
    },
    {
     "ename": "OptimizationError",
     "evalue": "Optimizer does not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptimizationError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/carlosperello/Desktop/M2R-Project/analysis/fit_hawkes.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlosperello/Desktop/M2R-Project/analysis/fit_hawkes.ipynb#ch0000009?line=11'>12</a>\u001b[0m         optimal_parameters[station\u001b[39m.\u001b[39mstart_id\u001b[39m.\u001b[39munique()[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m max_params\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlosperello/Desktop/M2R-Project/analysis/fit_hawkes.ipynb#ch0000009?line=12'>13</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/carlosperello/Desktop/M2R-Project/analysis/fit_hawkes.ipynb#ch0000009?line=13'>14</a>\u001b[0m         \u001b[39mraise\u001b[39;00m OptimizationError(\u001b[39m\"\u001b[39m\u001b[39mOptimizer does not converge\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlosperello/Desktop/M2R-Project/analysis/fit_hawkes.ipynb#ch0000009?line=14'>15</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlosperello/Desktop/M2R-Project/analysis/fit_hawkes.ipynb#ch0000009?line=15'>16</a>\u001b[0m optimal_parameters\n",
      "\u001b[0;31mOptimizationError\u001b[0m: Optimizer does not converge"
     ]
    }
   ],
   "source": [
    "class OptimizationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "optimal_parameters = {}\n",
    "for station in train_sorted_stations:\n",
    "    print(station.start_id.unique()[0])\n",
    "    x0 = [rates_dict[station.start_id.unique()[0]],2,10]\n",
    "    op_hawkes_likelihood = lambda x: -hawkes_log_likelihood(station.start_time.to_numpy(), np.exp(x[0]), np.exp(x[1]), np.exp(x[2]) + np.exp(x[1]))\n",
    "    sol = op.minimize(op_hawkes_likelihood, x0)\n",
    "    if sol.success:\n",
    "        max_params = sol.x\n",
    "        optimal_parameters[station.start_id.unique()[0]] = max_params\n",
    "    else:\n",
    "        raise OptimizationError(\"Optimizer does not converge\")\n",
    "        break\n",
    "optimal_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compensator(t, alpha, beta, lambda_p):\n",
    "    comp = []\n",
    "    for k in range(len(t)):\n",
    "        app = 0\n",
    "        app += t[k]*lambda_p\n",
    "        for i in range(0,k+1):\n",
    "            app += (alpha/beta) * np.exp(-beta * (t[k] - t[i]))\n",
    "\n",
    "def goodcompensator(t, alpha, beta, lambda_p):\n",
    "    result = []\n",
    "    for tk in t:\n",
    "        app = lambda_p*tk - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = list(optimal_parameters.keys())\n",
    "alphas = [item[0] for item in optimal_parameters.values()]\n",
    "betas = [item[1] for item in optimal_parameters.values()]\n",
    "lambdas = [item[2] for item in optimal_parameters.values()]\n",
    "#hawkes_parameters = pd.DataFrame((optimal_parameters.values()), columns = [\"alpha\", \"beta\", \"lambda\" ], index=optimal_parameters.keys())\n",
    "#hawkes_parameters.to_csv('../data/hawkes_parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404.5913763657923"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hawkes_parameters = pd.read_csv('../data/hawkes_parameters.csv', index_col=0)\n",
    "zeroth_case = hawkes_parameters.to_numpy()[0]\n",
    "zeroth_time = train_sorted_stations[0].start_time.to_numpy()\n",
    "compensated_times = compensator(zeroth_time, zeroth_case[0], zeroth_case[1], zeroth_case[2])\n",
    "compensated_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c982c42cf71dfd9e4fcac0d9653e64d0ee7da81b005f55f464a28429eb0786e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('M2R_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
