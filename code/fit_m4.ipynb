{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import scipy.optimize as op\n",
    "from tqdm import tqdm\n",
    "#from preprocessing import *\n",
    "plt.style.use(\"dark_background\") # Config plots for dark mode, delete if on light mode\n",
    "plt.rcParams['figure.dpi'] = 150 # Hi-res plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(\"../data/santander_locations.csv\")\n",
    "\n",
    "\n",
    "class OptimizationError(RuntimeError):\n",
    "    \"\"\"Called when optimizer does not converge.\"\"\"\n",
    "    pass\n",
    "\n",
    "class StationIdError(IndexError):\n",
    "    \"\"\"Called when we try and read a non-existing station id.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_station_name(in_id):\n",
    "    \"\"\"Get station name from bike_data for a given id.\"\"\"\n",
    "    try:\n",
    "        return station_data[\n",
    "            station_data[\"Station.Id\"] == in_id].StationName.iloc[0]\n",
    "    except IndexError:\n",
    "        StationIdError(\"No station matching input ID\")\n",
    "\n",
    "\n",
    "bike_data = pd.read_csv(\"../data/processed_df.csv\", index_col=0)\n",
    "x = bike_data.min()[\"start_time\"]\n",
    "t_min = (x // 86400) * 86400\n",
    "bike_data[\"start_time\"] = (bike_data[\"start_time\"] - t_min) / 60\n",
    "bike_data[\"end_time\"] = (bike_data[\"end_time\"] - t_min) / 60\n",
    "bike_data[\"start_time\"] = bike_data[\"start_time\"] \\\n",
    "    + np.random.rand(*bike_data[\"start_time\"].shape)\n",
    "bike_data[\"end_time\"] = bike_data[\"end_time\"] \\\n",
    "    + np.random.rand(*bike_data[\"end_time\"].shape)\n",
    "bike_data[\"duration\"] = bike_data.end_time - bike_data.start_time\n",
    "bike_data = bike_data.sort_values(by=[\"start_time\"])\n",
    "\n",
    "train_time = 12*7*24*60\n",
    "train_bike_data = bike_data[bike_data.start_time <= train_time]\n",
    "test_bike_data = bike_data[bike_data.start_time > train_time]\n",
    "train_sorted_stations_start = []\n",
    "for st_id in train_bike_data.start_id.sort_values().unique():\n",
    "    train_sorted_stations_start.append(\n",
    "        train_bike_data[train_bike_data.start_id == st_id]\n",
    "        )\n",
    "test_sorted_stations = []\n",
    "for st_id in test_bike_data.start_id.sort_values().unique():\n",
    "    test_sorted_stations.append(\n",
    "        test_bike_data[test_bike_data.start_id == st_id]\n",
    "        )\n",
    "rates_dict = {}\n",
    "for station in test_sorted_stations:\n",
    "    time_elapsed = station.start_time.to_numpy()[-1] \\\n",
    "        - station.start_time.to_numpy()[0]\n",
    "    n_events = test_sorted_stations[0].size\n",
    "    rate = n_events / time_elapsed\n",
    "\n",
    "    rates_dict[station.start_id.unique()[0]] = rate\n",
    "station_array = list(rates_dict.keys())\n",
    "\n",
    "\n",
    "def ecdf(data):\n",
    "    # https://cmdlinetips.com/2019/05/empirical-cumulative-distribution-function-ecdf-in-python/\n",
    "    \"\"\" Compute ECDF \"\"\"\n",
    "    x = np.sort(data)\n",
    "    n = x.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return(x, y)\n",
    "\n",
    "\n",
    "tprime_per_station = {}\n",
    "for id in bike_data.end_id.unique():\n",
    "    unsorted_station_end_time = bike_data[bike_data.end_id == id]\n",
    "    sorted_station_end_time = unsorted_station_end_time.sort_values(\n",
    "        by=[\"end_time\"])\n",
    "    tprime_per_station[id] = sorted_station_end_time.\\\n",
    "        end_time.to_numpy()\n",
    "tprime_per_station\n",
    "\n",
    "t_per_station = {}\n",
    "for id in bike_data.start_id.unique():\n",
    "    unsorted_station_start_time = bike_data[bike_data.start_id == id]\n",
    "    sorted_station_start_time = unsorted_station_start_time.sort_values(\n",
    "        by=[\"start_time\"])\n",
    "    t_per_station[id] = sorted_station_start_time.\\\n",
    "        start_time.to_numpy()\n",
    "\n",
    "sorted_start_ids = np.sort(bike_data.start_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], shape=(1, 0), dtype=float64), array([[0.9]]), array([[0.8]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def N(t_scalar, t):\n",
    "    \"\"\"\n",
    "    Returns the number of times in t less than or equal to t_scalar.\n",
    "    Is used to compute N(t_{i,k}) and N'(t_{i,k}) depending on whether t above is t or t_prime\n",
    "    \"\"\"\n",
    "\n",
    "    return np.searchsorted(t, t_scalar, side=\"right\")\n",
    "\n",
    "def getTimeDifferences(t, t_prime):\n",
    "    \"\"\"\n",
    "    Input: (sorted) times for a particular station i\n",
    "    Output: List of differences indexed by [h][k] for this station i\n",
    "    \"\"\"\n",
    "\n",
    "    # h goes until N(t[-1], t) assuming T = t[-1]\n",
    "    T = t[-1]\n",
    "    D_result = []\n",
    "    for h in range(1, N(T, t)+1):\n",
    "        differences_list = []\n",
    "        # Construct list of t_ih - t'_ik for k = 1 to N'(T)\n",
    "        differences_list.append(t[h-1] - t_prime[N(t[h-2], t_prime):N(t[h-1], t_prime)])\n",
    "\n",
    "        D_result.append(np.array(differences_list))\n",
    "\n",
    "    return D_result\n",
    "\n",
    "getTimeDifferences(np.array([1,2,3]),np.array([1.1,2.2,3.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compensator_m4_t_values(t_scalar, t, t_prime):\n",
    "    \"\"\"\n",
    "    Computes the lists that are required for the compensator function outside of it (without the parameters)\n",
    "    \"\"\"\n",
    "    return t_scalar - t_prime[:N(t_scalar, t_prime)], t_scalar - t[:N(t_scalar, t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compensator_m4(t_scalar, t, t_prime, lambda_i, alpha_i, beta_i, alpha_i_prime, beta_i_prime):\n",
    "    \"\"\"\n",
    "    t_scalar: scalar value where Lambda_i(t) is to be evaluated\n",
    "    t_prime: list of arrival times at station i\n",
    "\n",
    "    NOTE: t_prime NEEDS TO BE SORTED HERE.\n",
    "    \"\"\"\n",
    "\n",
    "    term1 = lambda_i * t_scalar\n",
    "    term2 = -(alpha_i_prime / beta_i_prime) * np.sum(np.exp(-beta_i_prime * (t_scalar - t_prime[:N(t_scalar, t_prime)]))-1)\n",
    "    term3 = -(alpha_i / beta_i) * np.sum(np.exp(-beta_i * (t_scalar - t[:N(t_scalar, t)]))-1)\n",
    "    return term1 + term2 + term3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_compensator_m4(t_scalar, t_precomputed, t_prime_precomputed, lambda_i, alpha_i, beta_i, alpha_i_prime, beta_i_prime):\n",
    "    \"\"\"\n",
    "    Evaluates compensator using already pre-computed list terms so we don't compute it every time.\n",
    "    \"\"\"\n",
    "\n",
    "    term1 = lambda_i * t_scalar\n",
    "    term2 = -(alpha_i_prime / beta_i_prime) * np.sum(np.exp(-beta_i_prime * (t_prime_precomputed))-1)\n",
    "    term3 = -(alpha_i / beta_i) * np.sum(np.exp(-beta_i * (t_precomputed))-1)\n",
    "    return term1 + term2 + term3\n",
    "\n",
    "def new_m4_log_likelihood(t, t_prime, t_precomputed, t_prime_precomputed,\n",
    " alpha_i, beta_i, alpha_i_prime, beta_i_prime, lambda_i, time_differences):\n",
    "    \"\"\"\n",
    "    Gives log likelihood of our five parameters. \n",
    "    t: start times from station i\n",
    "    t_prime: end times at station i\n",
    "\n",
    "    NOTE: t_prime NEEDS TO BE SORTED HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    T = t[-1] # TODO: Is this how we get big T?\n",
    "\n",
    "    # Get A list\n",
    "    A_ = new_A(len(t), t, beta_i)\n",
    "\n",
    "    # Get B list \n",
    "    B_ = new_B(len(t), t, t_prime, beta_i_prime, time_differences)\n",
    "\n",
    "    term1 = np.sum(np.log(lambda_i + alpha_i_prime*B_[:len(t)+1] + alpha_i*A_[:len(t)+1]))\n",
    "\n",
    "    term2 = -new_compensator_m4(T, t_precomputed, t_prime_precomputed, lambda_i, alpha_i, beta_i, alpha_i_prime, beta_i_prime)\n",
    "\n",
    "    return term1 + term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_B(h, t, t_prime, beta, time_differences):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns a list of [B_i(1), ..., B_i(h)]\n",
    "\n",
    "    NOTE: t_prime NEEDS to be sorted here\n",
    "\n",
    "    time_differences: time differences double list for station i\n",
    "\n",
    "    Note all index variables such as h, k, etc start at 1, like the mathematical notation.\n",
    "    \"\"\"\n",
    "    B = [np.sum(np.exp(-beta*(t[0] - t_prime[:N(t[0], t_prime)])))]\n",
    "\n",
    "    # Append the rest\n",
    "    for l in range(2, h+1):\n",
    "        # First term in recursive formula for B_i(h)\n",
    "        term1 = np.exp(-beta*(t[l-1] - t[l-2])) * B[l-2]\n",
    "        term2 = np.sum(np.exp(-beta*(time_differences[l-1])))\n",
    "        B.append(term1 + term2)\n",
    "    return np.array(B)\n",
    "\n",
    "\n",
    "def new_A(h, t, beta):\n",
    "\n",
    "    A = []\n",
    "    for i in range(1, h+1):\n",
    "        if i==1:\n",
    "            A.append(0)\n",
    "        else:\n",
    "            A.append(np.exp(-1*beta*(t[i-1] - t[i-2]))*(1+A[i-2]))\n",
    "    return np.array(A)\n",
    "\n",
    "\n",
    "def m4_log_likelihood(t, t_prime, alpha_i, beta_i, alpha_i_prime, beta_i_prime, lambda_i, time_differences):\n",
    "    \"\"\"\n",
    "    Gives log likelihood of our five parameters. \n",
    "    t: start times from station i\n",
    "    t_prime: end times at station i\n",
    "\n",
    "    NOTE: t_prime NEEDS TO BE SORTED HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    T = t[-1] # TODO: Is this how we get big T?\n",
    "\n",
    "    # Get A list\n",
    "    A_ = new_A(len(t), t, beta_i)\n",
    "\n",
    "    # Get B list \n",
    "    B_ = new_B(len(t), t, t_prime, beta_i_prime, time_differences)\n",
    "\n",
    "    term1 = np.sum(np.log(lambda_i + alpha_i_prime*B_[:len(t)+1] + alpha_i*A_[:len(t)+1]))\n",
    "\n",
    "    term2 = -compensator_m4(T, t, t_prime, lambda_i, alpha_i, beta_i, alpha_i_prime, beta_i_prime)\n",
    "\n",
    "    return term1 + term2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARLOS: To use the pre-computed times, do the following to evaluate the log-likelihood inside the for loop for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t_per_station[st_id]\n",
    "t_prime = tprime_per_station[st_id] # Need to sort t_prime for likelihood function\n",
    "time_differences = time_diffs[st_id]\n",
    "\n",
    "# Compute precomputed lists\n",
    "t_precomputed, t_prime_precomputed = compensator_m4_t_values(end_T, t, t_prime)\n",
    "\n",
    "# Use likelihood with pre computed lists\n",
    "op_m3_likelihood = lambda x: -new_m4_log_likelihood(t, t_prime, t_precomputed, t_prime_precomputed, np.exp(x[0]), np.exp(x[0]) + np.exp(x[1]), np.exp(x[2]), time_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24355.750391336445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-24355.750391336445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test m4 likelihood function\n",
    "beta = 0.01\n",
    "\n",
    "t = t_per_station[1]\n",
    "t_prime = tprime_per_station[1]\n",
    "\n",
    "time_differences = getTimeDifferences(t, t_prime)\n",
    "t_precomputed, t_prime_precomputed = compensator_m4_t_values(t[-1], t, t_prime)\n",
    "\n",
    "print(m4_log_likelihood(t, t_prime, 0.01, 0.1, 0.01, 0.1, 0.1, time_differences))\n",
    "new_m4_log_likelihood(t, t_prime, t_precomputed, t_prime_precomputed, 0.01, 0.1, 0.01, 0.1, 0.1, time_differences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the parameters using likelihood optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = {}\n",
    "for st_id in sorted_start_ids:\n",
    "    t = t_per_station[st_id]\n",
    "    t_prime = tprime_per_station[st_id] # Need to sort t_prime for likelihood function\n",
    "    time_diffs[st_id] = getTimeDifferences(t, t_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_params = pd.read_csv(\"../data/N_M_params.csv\", index_col=0)\n",
    "model_3_params = pd.read_csv(\"../data/M3_train_params.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: [0.015159431533715118,\n",
       "  0.016239850865439456,\n",
       "  0.023225018835280133,\n",
       "  15.686985160762877,\n",
       "  0.002914192741909464],\n",
       " 2: [0.16727100089829353,\n",
       "  1.0848695552106118,\n",
       "  0.013800627906146298,\n",
       "  1.2454693176791114,\n",
       "  0.0013461239097086856]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_parameters = {}\n",
    "for st_id in sorted_start_ids[:2]:\n",
    "    \n",
    "    print(st_id)\n",
    "    x0 = -np.ones(5) * 3\n",
    "\n",
    "    # TODO: What bounds should we use here?\n",
    "    t = t_per_station[st_id]\n",
    "    t_prime = tprime_per_station[st_id] # Need to sort t_prime for likelihood function\n",
    "    time_differences = time_diffs[st_id]\n",
    "    t_precomputed, t_prime_precomputed = compensator_m4_t_values(t[-1], t, t_prime)\n",
    "\n",
    "    op_m4_log_likelihood = lambda x: -new_m4_log_likelihood(t, t_prime, t_precomputed, t_prime_precomputed,\n",
    "        np.exp(x[0]), np.exp(x[0]) + np.exp(x[1]), np.exp(x[2]), np.exp(x[2] + x[3]), np.exp(x[4]), time_differences)\n",
    "    \n",
    "    #op_m4_log_likelihood = lambda x: -m4_log_likelihood(t, t_prime, np.exp(x[0]),\n",
    "    #     np.exp(x[0]) + np.exp(x[1]), np.exp(x[2]), np.exp(x[2] + x[3]), np.exp(x[4]), time_differences)\n",
    "\n",
    "    sol = op.minimize(op_m4_log_likelihood, x0, method=\"Nelder-Mead\")\n",
    "\n",
    "    if sol.success:\n",
    "        transformed_alpha = np.exp(sol.x[0])\n",
    "        transformed_beta = np.exp(sol.x[0]) + np.exp(sol.x[1])\n",
    "        transformed_alpha_prime = np.exp(sol.x[2])\n",
    "        transformed_beta_prime = np.exp(sol.x[2]) + np.exp(sol.x[3])\n",
    "        transformed_lambda = np.exp(sol.x[4])\n",
    "        max_params = [transformed_alpha, transformed_beta, transformed_alpha_prime, transformed_beta_prime, transformed_lambda]\n",
    "        optimal_parameters[st_id] = max_params\n",
    "\n",
    "    else:\n",
    "        raise OptimizationError(f\"Failed to converge for station {st_id}.\")\n",
    "optimal_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2188281200.py:30: RuntimeWarning: overflow encountered in double_scalars\n",
      "  A.append(np.exp(-1*beta*(t[i-1] - t[i-2]))*(1+A[i-2]))\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2188281200.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  A.append(np.exp(-1*beta*(t[i-1] - t[i-2]))*(1+A[i-2]))\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2188281200.py:17: RuntimeWarning: overflow encountered in double_scalars\n",
      "  term1 = np.exp(-beta*(t[l-1] - t[l-2])) * B[l-2]\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2188281200.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  term1 = np.exp(-beta*(t[l-1] - t[l-2])) * B[l-2]\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2188281200.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  term2 = np.sum(np.exp(-beta*(time_differences[l-1])))\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2036894021.py:29: RuntimeWarning: invalid value encountered in log\n",
      "  term1 = np.sum(np.log(lambda_i + alpha_i_prime*B_[:len(t)+1] + alpha_i*A_[:len(t)+1]))\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2036894021.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  term2 = -(alpha_i_prime / beta_i_prime) * np.sum(np.exp(-beta_i_prime * (t_prime_precomputed))-1)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_72352\\2036894021.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  term3 = -(alpha_i / beta_i) * np.sum(np.exp(-beta_i * (t_precomputed))-1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Owner\\Desktop\\M2R-Project\\code\\fit_m4.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=12'>13</a>\u001b[0m op_m4_log_likelihood \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39m-\u001b[39mnew_m4_log_likelihood(t, t_prime, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=13'>14</a>\u001b[0m     t_precomputed, t_prime_precomputed, x[\u001b[39m0\u001b[39m], x[\u001b[39m1\u001b[39m], x[\u001b[39m2\u001b[39m], x[\u001b[39m3\u001b[39m], x[\u001b[39m4\u001b[39m], time_differences)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=15'>16</a>\u001b[0m \u001b[39m#op_m4_log_likelihood = lambda x: -m4_log_likelihood(t, t_prime, np.exp(x[0]),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=16'>17</a>\u001b[0m \u001b[39m#     np.exp(x[0]) + np.exp(x[1]), np.exp(x[2]), np.exp(x[2] + x[3]), np.exp(x[4]), time_differences)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=18'>19</a>\u001b[0m sol \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49mminimize(op_m4_log_likelihood, x0, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mNelder-Mead\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m sol\u001b[39m.\u001b[39msuccess:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=21'>22</a>\u001b[0m     optimal_parameters[st_id] \u001b[39m=\u001b[39m x0\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py:611\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/_minimize.py?line=607'>608</a>\u001b[0m     constraints \u001b[39m=\u001b[39m standardize_constraints(constraints, x0, meth)\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/_minimize.py?line=609'>610</a>\u001b[0m \u001b[39mif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnelder-mead\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/_minimize.py?line=610'>611</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_neldermead(fun, x0, args, callback, bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/_minimize.py?line=611'>612</a>\u001b[0m                                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/_minimize.py?line=612'>613</a>\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpowell\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/_minimize.py?line=613'>614</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_powell(fun, x0, args, callback, bounds, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\scipy\\optimize\\optimize.py:805\u001b[0m, in \u001b[0;36m_minimize_neldermead\u001b[1;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=802'>803</a>\u001b[0m \u001b[39mif\u001b[39;00m bounds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=803'>804</a>\u001b[0m     xcc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(xcc, lower_bound, upper_bound)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=804'>805</a>\u001b[0m fxcc \u001b[39m=\u001b[39m func(xcc)\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=806'>807</a>\u001b[0m \u001b[39mif\u001b[39;00m fxcc \u001b[39m<\u001b[39m fsim[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=807'>808</a>\u001b[0m     sim[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m xcc\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\scipy\\optimize\\optimize.py:464\u001b[0m, in \u001b[0;36m_wrap_function.<locals>.function_wrapper\u001b[1;34m(x, *wrapper_args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=461'>462</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunction_wrapper\u001b[39m(x, \u001b[39m*\u001b[39mwrapper_args):\n\u001b[0;32m    <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=462'>463</a>\u001b[0m     ncalls[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Owner/AppData/Local/Programs/Python/Python38-32/lib/site-packages/scipy/optimize/optimize.py?line=463'>464</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m function(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49m(wrapper_args \u001b[39m+\u001b[39;49m args))\n",
      "\u001b[1;32mc:\\Users\\Owner\\Desktop\\M2R-Project\\code\\fit_m4.ipynb Cell 15'\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=9'>10</a>\u001b[0m time_differences \u001b[39m=\u001b[39m time_diffs[st_id]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=10'>11</a>\u001b[0m t_precomputed, t_prime_precomputed \u001b[39m=\u001b[39m compensator_m4_t_values(t[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], t, t_prime)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=12'>13</a>\u001b[0m op_m4_log_likelihood \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39m-\u001b[39mnew_m4_log_likelihood(t, t_prime, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=13'>14</a>\u001b[0m     t_precomputed, t_prime_precomputed, x[\u001b[39m0\u001b[39;49m], x[\u001b[39m1\u001b[39;49m], x[\u001b[39m2\u001b[39;49m], x[\u001b[39m3\u001b[39;49m], x[\u001b[39m4\u001b[39;49m], time_differences)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=15'>16</a>\u001b[0m \u001b[39m#op_m4_log_likelihood = lambda x: -m4_log_likelihood(t, t_prime, np.exp(x[0]),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=16'>17</a>\u001b[0m \u001b[39m#     np.exp(x[0]) + np.exp(x[1]), np.exp(x[2]), np.exp(x[2] + x[3]), np.exp(x[4]), time_differences)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000019?line=18'>19</a>\u001b[0m sol \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mminimize(op_m4_log_likelihood, x0, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNelder-Mead\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Owner\\Desktop\\M2R-Project\\code\\fit_m4.ipynb Cell 6'\u001b[0m in \u001b[0;36mnew_m4_log_likelihood\u001b[1;34m(t, t_prime, t_precomputed, t_prime_precomputed, alpha_i, beta_i, alpha_i_prime, beta_i_prime, lambda_i, time_differences)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000005?line=23'>24</a>\u001b[0m A_ \u001b[39m=\u001b[39m new_A(\u001b[39mlen\u001b[39m(t), t, beta_i)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000005?line=25'>26</a>\u001b[0m \u001b[39m# Get B list \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000005?line=26'>27</a>\u001b[0m B_ \u001b[39m=\u001b[39m new_B(\u001b[39mlen\u001b[39;49m(t), t, t_prime, beta_i_prime, time_differences)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000005?line=28'>29</a>\u001b[0m term1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(lambda_i \u001b[39m+\u001b[39m alpha_i_prime\u001b[39m*\u001b[39mB_[:\u001b[39mlen\u001b[39m(t)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m alpha_i\u001b[39m*\u001b[39mA_[:\u001b[39mlen\u001b[39m(t)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000005?line=30'>31</a>\u001b[0m term2 \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnew_compensator_m4(T, t_precomputed, t_prime_precomputed, lambda_i, alpha_i, beta_i, alpha_i_prime, beta_i_prime)\n",
      "\u001b[1;32mc:\\Users\\Owner\\Desktop\\M2R-Project\\code\\fit_m4.ipynb Cell 7'\u001b[0m in \u001b[0;36mnew_B\u001b[1;34m(h, t, t_prime, beta, time_differences)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000006?line=16'>17</a>\u001b[0m     term1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mbeta\u001b[39m*\u001b[39m(t[l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m t[l\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m])) \u001b[39m*\u001b[39m B[l\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000006?line=17'>18</a>\u001b[0m     term2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mbeta\u001b[39m*\u001b[39m(time_differences[l\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000006?line=18'>19</a>\u001b[0m     B\u001b[39m.\u001b[39;49mappend(term1 \u001b[39m+\u001b[39m term2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/M2R-Project/code/fit_m4.ipynb#ch0000006?line=19'>20</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(B)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimal_parameters = {}\n",
    "for st_id in sorted_start_ids[:2]:\n",
    "    \n",
    "    print(st_id)\n",
    "    x0 = np.exp(-np.ones(5) * 3)\n",
    "\n",
    "    # TODO: What bounds should we use here?\n",
    "    t = t_per_station[st_id]\n",
    "    t_prime = tprime_per_station[st_id] # Need to sort t_prime for likelihood function\n",
    "    time_differences = time_diffs[st_id]\n",
    "    t_precomputed, t_prime_precomputed = compensator_m4_t_values(t[-1], t, t_prime)\n",
    "\n",
    "    op_m4_log_likelihood = lambda x: -new_m4_log_likelihood(t, t_prime, \n",
    "        t_precomputed, t_prime_precomputed, x[0], x[1], x[2], x[3], x[4], time_differences)\n",
    "    \n",
    "    #op_m4_log_likelihood = lambda x: -m4_log_likelihood(t, t_prime, np.exp(x[0]),\n",
    "    #     np.exp(x[0]) + np.exp(x[1]), np.exp(x[2]), np.exp(x[2] + x[3]), np.exp(x[4]), time_differences)\n",
    "\n",
    "    sol = op.minimize(op_m4_log_likelihood, x0, method=\"Nelder-Mead\")\n",
    "\n",
    "    if sol.success:\n",
    "        optimal_parameters[st_id] = x0\n",
    "\n",
    "    else:\n",
    "        raise OptimizationError(f\"Failed to converge for station {st_id}.\")\n",
    "optimal_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing fit for model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c1410969137b62557f626ec5944e60126207e5e8b8864d3436c9c9d7a53b4e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
